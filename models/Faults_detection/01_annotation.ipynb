{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faults annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here will show annotation format and structure of faults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from copy import copy\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from seismiqb import *\n",
    "from seismiqb.src.controllers.torch_models import ExtensionModel\n",
    "\n",
    "from seismiqb.batchflow import FilesIndex, Pipeline\n",
    "from seismiqb.batchflow import D, B, V, P, R, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faults can be sored in different formats (see `Fault` class documentation).\n",
    "In our case each csv-like file corresponds to one fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUBE_FOLDER = '/data/seismic_data/seismic_interpretation/CUBE_16_PSDM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault = glob.glob(CUBE_FOLDER + '/INPUTS/FAULTS/RAW/*')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns are `['INLINE', 'iline', 'xline', 'cdp_x', 'cdp_y', 'height', 'name', 'number']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head \"{fault}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we check that all files have known structure. Otherwise, we have to fix some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fault.check_format(CUBE_FOLDER + '/INPUTS/FAULTS/RAW/*', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the loading stage, we interpolate each fault as a surface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cube_path = glob.glob(CUBE_FOLDER + '/amp*.hdf5')[0]\n",
    "\n",
    "dataset = SeismicCubeset(FilesIndex(path=cube_path, no_ext=True))\n",
    "\n",
    "dataset.load(label_dir='/INPUTS/FAULTS/RAW/*', labels_class=Fault, width=3)\n",
    "dataset.modify_sampler(dst='train_sampler', finish=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sticks interpolation is time consuming procedure, therefore we dump resulting points as a `.npy` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dump_labels('/INPUTS/FAULTS/NPY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and make loading faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset = SeismicCubeset(FilesIndex(path=cube_path, no_ext=True))\n",
    "\n",
    "dataset.load(label_dir='/INPUTS/FAULTS/NPY/*', labels_class=Fault)\n",
    "dataset.modify_sampler(dst='train_sampler', finish=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of faults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the map of faults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.show_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And slice from the cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = dataset.labels[0][0].points[0, 0]\n",
    "zoom_slice = (slice(None), slice(900, 1500))\n",
    "dataset.show_slide(i, zoom_slice=zoom_slice, figsize=(20, 10), mode='separate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.show_slide(i, zoom_slice=zoom_slice, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
